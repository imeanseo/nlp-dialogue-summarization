import pandas as pd
import requests
import json
import time
from tqdm import tqdm
import os
import re
from collections import Counter, defaultdict
import concurrent.futures


def clean_dialogue(dialogue_str):
    lines = dialogue_str.strip().split('\n')
    cleaned = []
    for line in lines:
        line = line.strip()
        if line and not line.startswith('---'):
            cleaned.append(line)
    return ' '.join(cleaned)


def detect_speech_style(dialogue):
    dialogue = dialogue.lower()
    honorific_count = len(re.findall(r'[í•´|í•©ë‹ˆë‹¤|ì„¸ìš”|ì£¼|ë“œ|ì‹œ|ã…‚ë‹ˆë‹¤]', dialogue))
    plain_count = len(re.findall(r'í•´|í•œë‹¤|ì•¼|ì§€|ë„¤|êµ¬ë‚˜', dialogue))
    if honorific_count > plain_count * 1.5:
        return "ì¡´ëŒ“ë§ (-ìŠµë‹ˆë‹¤/í•©ë‹ˆë‹¤ ì²´)"
    else:
        return "ë°˜ë§ (í•œë‹¤/í•´ ì²´)"


def extract_real_examples(df, n_examples_per_topic=2):
    examples = {}
    for topic in df['topic'].unique():
        topic_df = df[df['topic'] == topic].head(10)
        topic_samples = topic_df.sample(n=min(n_examples_per_topic, len(topic_df)), random_state=42)
        topic_examples = []
        for _, row in topic_samples.iterrows():
            dialogue = clean_dialogue(row['dialogue'])
            summary = row['summary']
            style = detect_speech_style(dialogue)
            example = f"""ì˜ˆì‹œ ({style}):
ëŒ€í™”: {dialogue[:200]}...
ìš”ì•½: {summary}"""
            topic_examples.append(example)
        examples[topic] = "\n".join(topic_examples)
    return examples


def solar_real_data_fewshot_prompt(dialogue, topic, real_examples):
    style = detect_speech_style(dialogue)
    base_rules = f"""ë‹¤ìŒ ëŒ€í™”ì˜ í•µì‹¬ë§Œ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ğŸ“‹ í•„ìˆ˜ ê·œì¹™:
1. "#Person1#ì´ #Person2#ì—ê²Œ ..." í˜•ì‹ ë°˜ë“œì‹œ ì‚¬ìš©
2. ë¬¸ì²´: {style} (ëŒ€í™” ë”°ë¼ ìë™ ì ìš©)
3. í•µì‹¬ë§Œ! (ë“±ì¥ì¸ë¬¼+í–‰ë™+ê²°ê³¼, 50-100ì)
4. ë””í…Œì¼/ëŒ€í™” ì¸ìš©/ë°˜ë³µ í‘œí˜„ ì œì™¸"""

    topic_examples = real_examples.get(topic, "")
    return f"""{base_rules}

ğŸ“š {topic} ì£¼ì œ ì‹¤ì œ ì˜ˆì‹œ:
{topic_examples}

ğŸ¯ ì´ë²ˆ ëŒ€í™”:
{dialogue}

ìš”ì•½:"""


API_KEY = "secret" 
API_URL = "https://api.upstage.ai/v1/chat/completions"
MODEL_NAME = "solar-pro2"


def call_solar(prompt: str) -> str:
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }
    data = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 100,
        "stream": False,
    }
    try:
        resp = requests.post(API_URL, json=data, headers=headers, timeout=120)
        resp.raise_for_status()
        j = resp.json()
        return j["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"ìš”ì²­ ì˜¤ë¥˜: {e}")
        return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"


def augment_sample(row, real_examples):
    prompt = solar_real_data_fewshot_prompt(row['dialogue'], row['topic'], real_examples)
    summary = call_solar(prompt)
    return {
        'dialogue': row['dialogue'],
        'summary': summary,
        'topic': row['topic'],
        'source': 'solar_real_fewshot'
    }


def balanced_topic_augmentation(df, min_samples_per_topic=10, augment_ratio=3):
    print("ğŸ” ì‹¤ì œ train.csvì—ì„œ í† í”½ë³„ Few-shot ì˜ˆì‹œ ì¶”ì¶œ ì¤‘...")
    real_examples = extract_real_examples(df)

    df['dialogue'] = df['dialogue'].apply(clean_dialogue)
    topic_counts = df['topic'].value_counts()

    print("\nğŸ“Š ì›ë³¸ í† í”½ ë¶„í¬ (ìƒìœ„ 10):")
    print(topic_counts.head(10))

    # ğŸš€ í•„í„°ë§: ìƒ˜í”Œ 3ê°œ ì´ìƒ í† í”½ë§Œ ì„ íƒ
    filtered_topics = topic_counts[topic_counts >= 3].index
    print(f"\nğŸ” ì¦ê°• ëŒ€ìƒ í† í”½: {len(filtered_topics)}ê°œ (ìƒ˜í”Œ 3ê°œ ì´ìƒ)")

    results = []
    save_path = "data/augmented/train_solar_real_fewshot_partial.csv"
    os.makedirs("data/augmented", exist_ok=True)

    for topic in tqdm(filtered_topics, desc="í† í”½ë³„ ì¦ê°•"):
        topic_df = df[df['topic'] == topic]
        current_count = len(topic_df)

        # ì›ë³¸ ë°ì´í„° ì „ë¶€ í¬í•¨
        for _, row in topic_df.iterrows():
            results.append({
                'dialogue': row['dialogue'],
                'summary': row['summary'],
                'topic': topic,
                'source': 'original'
            })

        # 10ê°œ ë¯¸ë§Œì´ë©´ 10ê°œë¡œ ì¦ê°•
        target_count = min_samples_per_topic
        if current_count < target_count:
            need_augment = target_count - current_count
            print(f"\nğŸ¯ {topic}: {current_count}â†’{target_count} (+{need_augment})")

            augment_samples = topic_df.sample(
                min(need_augment * augment_ratio, len(topic_df)),
                random_state=42
            )

            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                futures = [executor.submit(augment_sample, row, real_examples) for _, row in augment_samples.iterrows()]
                for i, future in enumerate(concurrent.futures.as_completed(futures)):
                    result = future.result()
                    results.append(result)
                    if i % 10 == 0:
                        pd.DataFrame(results).to_csv(save_path, index=False)

    pd.DataFrame(results).to_csv(save_path, index=False)
    print(f"\nâœ… ì¤‘ê°„ ê²°ê³¼ë¥¼ {save_path} ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    return pd.DataFrame(results), real_examples


if __name__ == "__main__":
    print("ğŸš€ V6 ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í† í”½ë³„ Few-shot ì¦ê°•")
    print("ğŸ¯ ëª©í‘œ: í† í”½ë‹¹ ìµœì†Œ 10ê°œ + ë¬¸ì²´ ì •í™• ë°˜ì˜")

    df = pd.read_csv("/root/nlp_data/train.csv")
    print(f"ğŸ“‚ ì›ë³¸ ë°ì´í„° ë¡œë“œ: {len(df)} ìƒ˜í”Œ")

    aug_df, real_examples = balanced_topic_augmentation(df, min_samples_per_topic=10)

    final_save_path = "data/augmented/train_solar_real_fewshot.csv"
    aug_df.to_csv(final_save_path, index=False)

    with open("data/augmented/real_fewshot_examples.json", "w", encoding="utf-8") as f:
        json.dump(real_examples, f, ensure_ascii=False, indent=2)

    print("\nâœ… ì¦ê°• ì™„ë£Œ!")
    print(f"ì´ ìƒ˜í”Œ: {len(aug_df)}")
    print("\nğŸ“Š ì¦ê°• í›„ ê· í˜• (í•˜ìœ„ 10 í† í”½):")
    print(aug_df.groupby('topic').size().sort_values().head(10))
    print("\nğŸ“Š ì¦ê°• í›„ ê· í˜• (ìƒìœ„ 10 í† í”½):")
    print(aug_df.groupby('topic').size().sort_values(ascending=False).head(10))

    print("\nğŸ”¥ Solar ì¦ê°• ìƒ˜í”Œ 5ê°œ:")
    display_df = aug_df[aug_df['source']=='solar_real_fewshot'][['topic', 'summary']].head(5)
    for _, row in display_df.iterrows():
        print(f"[{row['topic']}] {row['summary']}")

    # ìµœì¢… í•™ìŠµ ë°ì´í„° (ì›ë³¸ + ì¦ê°•)
    orig_train = pd.read_csv("/root/nlp_data/train.csv")
    orig_train['source'] = 'original_full'
    solar_only = aug_df[aug_df['source']=='solar_real_fewshot']
    v6_train = pd.concat([orig_train, solar_only])
    v6_train.to_csv("data/augmented/train_v6_perfect.csv", index=False)
    print(f"\nğŸ‰ V6 ìµœì¢… í•™ìŠµ ë°ì´í„°: {len(v6_train)} ìƒ˜í”Œ (ì›ë³¸+ì¦ê°•)")
