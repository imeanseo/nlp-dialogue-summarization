{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0955acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_metric\n",
    "\n",
    "BASE_DIR = \"/root/nlp_data\"\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"t5_large_v5\", \"final_model\")  # 네 output_dir/final_model 경로로 수정\n",
    "DEV_PATH = os.path.join(BASE_DIR, \"dev.csv\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR).to(\"cuda\")\n",
    "\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# dev 로드\n",
    "df_dev = pd.read_csv(DEV_PATH)[[\"dialogue\", \"summary\"]]\n",
    "dev_ds = Dataset.from_pandas(df_dev)\n",
    "\n",
    "def generate_batch(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"dialogue\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return preds\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "batch_size = 8\n",
    "for i in range(0, len(dev_ds), batch_size):\n",
    "    batch = dev_ds[i:i+batch_size]\n",
    "    preds = generate_batch(batch)\n",
    "    labels = [s.strip() for s in batch[\"summary\"]]\n",
    "    all_preds.extend([p.strip() for p in preds])\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "scores = rouge.compute(predictions=all_preds, references=all_labels, use_stemmer=True)\n",
    "print(\"ROUGE-1:\", scores[\"rouge1\"].mid.fmeasure)\n",
    "print(\"ROUGE-2:\", scores[\"rouge2\"].mid.fmeasure)\n",
    "print(\"ROUGE-L:\", scores[\"rougeL\"].mid.fmeasure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMSUM_VALID = os.path.join(BASE_DIR, \"samsum\", \"samsum_valid_ko.csv\")\n",
    "df_sv = pd.read_csv(SAMSUM_VALID)[[\"dialogue_ko\", \"summary_ko\"]]\n",
    "df_sv = df_sv.rename(columns={\"dialogue_ko\": \"dialogue\", \"summary_ko\": \"summary\"})\n",
    "sv_ds = Dataset.from_pandas(df_sv)\n",
    "\n",
    "# 위에서 만든 generate_batch 재사용\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "for i in range(0, len(sv_ds), batch_size):\n",
    "    batch = sv_ds[i:i+batch_size]\n",
    "    preds = generate_batch(batch)\n",
    "    labels = [s.strip() for s in batch[\"summary\"]]\n",
    "    all_preds.extend([p.strip() for p in preds])\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "scores_sv = rouge.compute(predictions=all_preds, references=all_labels, use_stemmer=True)\n",
    "print(\"SamSum-ko ROUGE-1:\", scores_sv[\"rouge1\"].mid.fmeasure)\n",
    "print(\"SamSum-ko ROUGE-2:\", scores_sv[\"rouge2\"].mid.fmeasure)\n",
    "print(\"SamSum-ko ROUGE-L:\", scores_sv[\"rougeL\"].mid.fmeasure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c5e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
